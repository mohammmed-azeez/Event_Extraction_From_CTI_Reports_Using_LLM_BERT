{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "directory = 'data'\n",
    "\n",
    "texts = []\n",
    "labels = []\n",
    "\n",
    "for filename in os.listdir(directory):\n",
    "    if filename.endswith('.txt'):  \n",
    "        with open(os.path.join(directory, filename), 'r', encoding='utf-8') as file:\n",
    "            for line in file:\n",
    "                if '|' in line:\n",
    "                    parts = line.rsplit('|', 1)\n",
    "                    if parts[1].strip() == \"\":\n",
    "                        continue\n",
    "                    text = parts[0].strip()\n",
    "                    label = parts[1].strip() if len(parts) > 1 else 'O'  \n",
    "                    texts.append(text)\n",
    "                    labels.append(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'O': 10209,\n",
       "         'AttackRansom': 1494,\n",
       "         'AttackRansom, AttackDatabreach': 24,\n",
       "         'DiscoverVulnerability': 1467,\n",
       "         'AttackDatabreach': 1405,\n",
       "         'PatchVulnerability': 949,\n",
       "         'AttackPhishing': 1283,\n",
       "         'PatchVulnerability, DiscoverVulnerability': 83,\n",
       "         'DiscoverVulnerability , PatchVulnerability': 40,\n",
       "         'DiscoverVulnerability, PatchVulnerability': 121,\n",
       "         'AttackPhishing, AttackDatabreach': 26,\n",
       "         'AttackDatabreach, AttackPhishing': 21,\n",
       "         'DiscoverVulnerability, AttackDatabreach': 22,\n",
       "         'PatchVulnerability, AttackRansom': 4,\n",
       "         'PatchVulnerability , DiscoverVulnerability': 9,\n",
       "         'DiscoverVulnerability, AttackPhishing': 2,\n",
       "         'AttackRansom, AttackDatabreach, AttackPhishing': 1,\n",
       "         'AttackDatabreach, AttackRansom': 14,\n",
       "         'PatchVulnerability , AttackDatabreach': 1,\n",
       "         'AttackDatabreach, DiscoverVulnerability': 8,\n",
       "         'AttackDatabreach, PatchVulnerability': 3,\n",
       "         'AttackRansom, DiscoverVulnerability': 1,\n",
       "         'AttackPhishing, PatchVulnerability': 6,\n",
       "         'PatchVulnerability,  DiscoverVulnerability': 1,\n",
       "         'DiscoverVulnerability,PatchVulnerability': 1,\n",
       "         'AttackPhishing , AttackRansom': 4,\n",
       "         'AttackDatabreach , AttackRansom': 11,\n",
       "         'AttackDatabreach , DiscoverVulnerability': 2,\n",
       "         'AttackPhishing , AttackDatabreach': 9,\n",
       "         'AttackRansom, AttackPhishing': 3,\n",
       "         'AttackDatabreach , AttackPhishing': 6,\n",
       "         'AttackPhishing , PatchVulnerability': 1,\n",
       "         'PatchVulnerability , AttackRansom': 1,\n",
       "         'AttackRansom , AttackDatabreach': 6,\n",
       "         'AttackRansom, PatchVulnerability': 2,\n",
       "         'PatchVulnerability, AttackPhishing': 3,\n",
       "         'DiscoverVulnerability, AttackRansom': 2,\n",
       "         'DiscoverVulnerability , AttackDatabreach': 8,\n",
       "         'PatchVulnerability, AttackDatabreach': 1,\n",
       "         'AttackPhishing, AttackRansom': 6,\n",
       "         'AttackPhishing, AttackRansom, PatchVulnerability': 1,\n",
       "         'DiscoverVulnerability , AttackRansom': 1,\n",
       "         'AttackRansom , DiscoverVulnerability': 2,\n",
       "         'AttackRansom , AttackDatabreach , AttackRansom': 1,\n",
       "         'AttackRansom , PatchVulnerability': 1,\n",
       "         'AttackDatabreach , AttackDatabreach': 1,\n",
       "         'AttackPhishing, DiscoverVulnerability': 1,\n",
       "         'AttackRansom , AttackPhishing': 1})"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "Counter(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp  = []\n",
    "for label in labels:\n",
    "    for t in label.split(','):\n",
    "        temp.append(t.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'O': 10209,\n",
       "         'AttackRansom': 1581,\n",
       "         'AttackDatabreach': 1571,\n",
       "         'DiscoverVulnerability': 1771,\n",
       "         'PatchVulnerability': 1228,\n",
       "         'AttackPhishing': 1374})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>AttackDatabreach</th>\n",
       "      <th>AttackPhishing</th>\n",
       "      <th>AttackRansom</th>\n",
       "      <th>DiscoverVulnerability</th>\n",
       "      <th>PatchVulnerability</th>\n",
       "      <th>O</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Attackers start wiping data from CouchDB and H...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Researchers are now observing similar destruct...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Security researchers Victor Gevers and Niall M...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The two have put together spreadsheets on Goog...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>In the case of Hadoop, a framework used for di...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17264</th>\n",
       "      <td>\"Ransomware has become a billion-dollar cash c...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17265</th>\n",
       "      <td>In order to help prevent falling victim to ran...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17266</th>\n",
       "      <td>Launched in 2016, the No More Ransom scheme br...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17267</th>\n",
       "      <td>The portal is available in 29 languages and si...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17268</th>\n",
       "      <td>The release of GandCrab decryption tools comes...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>17269 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    Text  AttackDatabreach  \\\n",
       "0      Attackers start wiping data from CouchDB and H...                 0   \n",
       "1      Researchers are now observing similar destruct...                 0   \n",
       "2      Security researchers Victor Gevers and Niall M...                 0   \n",
       "3      The two have put together spreadsheets on Goog...                 0   \n",
       "4      In the case of Hadoop, a framework used for di...                 0   \n",
       "...                                                  ...               ...   \n",
       "17264  \"Ransomware has become a billion-dollar cash c...                 0   \n",
       "17265  In order to help prevent falling victim to ran...                 0   \n",
       "17266  Launched in 2016, the No More Ransom scheme br...                 0   \n",
       "17267  The portal is available in 29 languages and si...                 0   \n",
       "17268  The release of GandCrab decryption tools comes...                 0   \n",
       "\n",
       "       AttackPhishing  AttackRansom  DiscoverVulnerability  \\\n",
       "0                   0             0                      0   \n",
       "1                   0             0                      0   \n",
       "2                   0             0                      0   \n",
       "3                   0             0                      0   \n",
       "4                   0             0                      0   \n",
       "...               ...           ...                    ...   \n",
       "17264               0             0                      0   \n",
       "17265               0             0                      0   \n",
       "17266               0             1                      0   \n",
       "17267               0             0                      0   \n",
       "17268               0             0                      0   \n",
       "\n",
       "       PatchVulnerability  O  \n",
       "0                       0  1  \n",
       "1                       0  1  \n",
       "2                       0  1  \n",
       "3                       0  1  \n",
       "4                       0  1  \n",
       "...                   ... ..  \n",
       "17264                   0  1  \n",
       "17265                   0  1  \n",
       "17266                   0  0  \n",
       "17267                   0  1  \n",
       "17268                   0  1  \n",
       "\n",
       "[17269 rows x 7 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    'Text': texts,\n",
    "    'Label': labels\n",
    "})\n",
    "\n",
    "all_labels = [\"AttackDatabreach\", \"AttackPhishing\", \"AttackRansom\", \"DiscoverVulnerability\", \"PatchVulnerability\",\"O\"]\n",
    "\n",
    "\n",
    "def label_columns(row, label_list):\n",
    "    label_data = {label: 0 for label in label_list}\n",
    "    entries = row['Label'].split(',')\n",
    "    for entry in entries:\n",
    "        entry = entry.strip()\n",
    "        if entry in label_data:\n",
    "            label_data[entry] = 1\n",
    "    return pd.Series(label_data)\n",
    "\n",
    "label_df = df.apply(lambda row: label_columns(row, all_labels), axis=1)\n",
    "\n",
    "\n",
    "final_df = pd.concat([df['Text'], label_df], axis=1)\n",
    "final_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label2id: {'AttackDatabreach': 0, 'AttackPhishing': 1, 'AttackRansom': 2, 'DiscoverVulnerability': 3, 'PatchVulnerability': 4, 'O': 5}\n",
      "id2label: {0: 'AttackDatabreach', 1: 'AttackPhishing', 2: 'AttackRansom', 3: 'DiscoverVulnerability', 4: 'PatchVulnerability', 5: 'O'}\n"
     ]
    }
   ],
   "source": [
    "labels = [\"AttackDatabreach\", \"AttackPhishing\", \"AttackRansom\", \"DiscoverVulnerability\", \"PatchVulnerability\", \"O\"]\n",
    "\n",
    "# Create label2id dictionary\n",
    "label2id = {label: i for i, label in enumerate(labels)}\n",
    "\n",
    "# Create id2label dictionary\n",
    "id2label = {i: label for i, label in enumerate(labels)}\n",
    "\n",
    "# Output the dictionaries\n",
    "print(\"label2id:\", label2id)\n",
    "print(\"id2label:\", id2label)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "20aee6181bde4ff49101fae5ae01ed4d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/17269 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "47212534cfd24d70b566d178ec51f57e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/17269 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/home/is1ab/anaconda3/envs/coref/lib/python3.7/site-packages/transformers/optimization.py:415: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  FutureWarning,\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mt111599004\u001b[0m (\u001b[33mntut-biolab\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.17.4 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.10"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/is1ab/code/Event-Extraction-from-Cyber-Threat-Report-Using-BERT-Model/wandb/run-20240713_170158-vwg6xany</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/ntut-biolab/huggingface/runs/vwg6xany' target=\"_blank\">young-snowflake-148</a></strong> to <a href='https://wandb.ai/ntut-biolab/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/ntut-biolab/huggingface' target=\"_blank\">https://wandb.ai/ntut-biolab/huggingface</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/ntut-biolab/huggingface/runs/vwg6xany' target=\"_blank\">https://wandb.ai/ntut-biolab/huggingface/runs/vwg6xany</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a BertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='4320' max='4320' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [4320/4320 1:10:00, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.170718</td>\n",
       "      <td>0.831597</td>\n",
       "      <td>0.796831</td>\n",
       "      <td>0.811533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.231500</td>\n",
       "      <td>0.157981</td>\n",
       "      <td>0.839505</td>\n",
       "      <td>0.807583</td>\n",
       "      <td>0.821488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.128700</td>\n",
       "      <td>0.178294</td>\n",
       "      <td>0.823116</td>\n",
       "      <td>0.804188</td>\n",
       "      <td>0.809432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.087000</td>\n",
       "      <td>0.187704</td>\n",
       "      <td>0.816062</td>\n",
       "      <td>0.804754</td>\n",
       "      <td>0.808804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.056500</td>\n",
       "      <td>0.208515</td>\n",
       "      <td>0.821589</td>\n",
       "      <td>0.791171</td>\n",
       "      <td>0.803554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.039500</td>\n",
       "      <td>0.225088</td>\n",
       "      <td>0.819952</td>\n",
       "      <td>0.815507</td>\n",
       "      <td>0.816034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.027100</td>\n",
       "      <td>0.233527</td>\n",
       "      <td>0.824789</td>\n",
       "      <td>0.813243</td>\n",
       "      <td>0.817461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.027100</td>\n",
       "      <td>0.236844</td>\n",
       "      <td>0.815463</td>\n",
       "      <td>0.807583</td>\n",
       "      <td>0.810445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.021500</td>\n",
       "      <td>0.245484</td>\n",
       "      <td>0.818670</td>\n",
       "      <td>0.810979</td>\n",
       "      <td>0.813508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.016900</td>\n",
       "      <td>0.246568</td>\n",
       "      <td>0.818185</td>\n",
       "      <td>0.810413</td>\n",
       "      <td>0.812824</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=4320, training_loss=0.07158374488353729, metrics={'train_runtime': 4206.3193, 'train_samples_per_second': 32.843, 'train_steps_per_second': 1.027, 'total_flos': 3.63500977425408e+16, 'train_loss': 0.07158374488353729, 'epoch': 10.0})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from datasets import Dataset\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, TrainingArguments, Trainer\n",
    "import torch\n",
    "import pandas as pd\n",
    "from datasets import Dataset\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, TrainingArguments, Trainer\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score\n",
    "import numpy as np\n",
    "from transformers import DataCollatorWithPadding\n",
    "\n",
    "dataset = Dataset.from_pandas(final_df)\n",
    "tokenizer = AutoTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "def tokenize_function(examples):\n",
    "    return tokenizer(examples['Text'], padding=\"max_length\", truncation=True)\n",
    "\n",
    "tokenized_datasets = dataset.map(tokenize_function, batched=True)\n",
    "\n",
    "# Convert integer labels to floats for BCEWithLogitsLoss\n",
    "def format_labels(example):\n",
    "    labels = [float(example[col]) for col in ['AttackDatabreach', 'AttackPhishing', 'AttackRansom', \n",
    "                                              'DiscoverVulnerability', 'PatchVulnerability', 'O']]\n",
    "    return {'labels': labels}\n",
    "\n",
    "tokenized_datasets = tokenized_datasets.map(format_labels)\n",
    "\n",
    "# Split the dataset into train, validation, and test sets\n",
    "train_testvalid = tokenized_datasets.train_test_split(test_size=0.2, shuffle=True)\n",
    "test_valid = train_testvalid['test'].train_test_split(test_size=0.5, shuffle=True)\n",
    "train_dataset = train_testvalid['train']\n",
    "valid_dataset = test_valid['train']\n",
    "test_dataset = test_valid['test']\n",
    "\n",
    "# Metrics computation\n",
    "import numpy as np\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    # Apply sigmoid function to logits and threshold at 0.5 for binary prediction\n",
    "    preds = (1 / (1 + np.exp(-logits)) > 0.5).astype(float)\n",
    "    precision = precision_score(labels, preds, average='weighted')\n",
    "    recall = recall_score(labels, preds, average='weighted')\n",
    "    f1 = f1_score(labels, preds, average='weighted')\n",
    "    return {'precision': precision, 'recall': recall, 'f1': f1}\n",
    "\n",
    "\n",
    "\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n",
    "# Training\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./results',\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=32,\n",
    "    num_train_epochs=10,\n",
    "    weight_decay=0.01\n",
    ")\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=6, problem_type=\"multi_label_classification\")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=valid_dataset,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='216' max='216' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [216/216 00:18]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.2451830953359604,\n",
       " 'eval_precision': 0.8347406598219786,\n",
       " 'eval_recall': 0.8228990411731528,\n",
       " 'eval_f1': 0.8261504714057493,\n",
       " 'eval_runtime': 18.7643,\n",
       " 'eval_samples_per_second': 92.036,\n",
       " 'eval_steps_per_second': 11.511,\n",
       " 'epoch': 10.0}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluate on test data\n",
    "trainer.evaluate(test_dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('./saved_model/tokenizer_config.json',\n",
       " './saved_model/special_tokens_map.json',\n",
       " './saved_model/vocab.txt',\n",
       " './saved_model/added_tokens.json',\n",
       " './saved_model/tokenizer.json')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_path = \"./saved_model\"\n",
    "model.save_pretrained(model_path)\n",
    "tokenizer.save_pretrained(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                       precision    recall  f1-score   support\n",
      "\n",
      "     AttackDatabreach       0.67      0.35      0.46       304\n",
      "       AttackPhishing       0.90      0.48      0.63       268\n",
      "         AttackRansom       0.87      0.64      0.74       326\n",
      "DiscoverVulnerability       0.78      0.44      0.56       354\n",
      "                    O       0.80      0.87      0.84      2051\n",
      "   PatchVulnerability       0.87      0.54      0.67       243\n",
      "\n",
      "            micro avg       0.81      0.71      0.76      3546\n",
      "            macro avg       0.82      0.55      0.65      3546\n",
      "         weighted avg       0.81      0.71      0.74      3546\n",
      "          samples avg       0.72      0.72      0.72      3546\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/is1ab/anaconda3/envs/coref/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# baseline\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "\n",
    "\n",
    "\n",
    "# Convert labels to a list of sets for MultiLabelBinarizer\n",
    "labels = final_df[['AttackDatabreach', 'AttackPhishing', 'AttackRansom', \n",
    "                   'DiscoverVulnerability', 'PatchVulnerability', 'O']].apply(\n",
    "    lambda x: set(x[x == 1].index), axis=1)\n",
    "\n",
    "# Binarize the labels\n",
    "mlb = MultiLabelBinarizer()\n",
    "y = mlb.fit_transform(labels)\n",
    "\n",
    "# Ensure you have the correct number of text samples and labels\n",
    "assert len(final_df['Text']) == len(y), \"Mismatch in number of samples between Text and labels.\"\n",
    "\n",
    "# Feature extraction\n",
    "vectorizer = TfidfVectorizer(max_features=1000)\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(final_df['Text'], y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Logistic Regression in a OneVsRest framework\n",
    "pipeline = Pipeline([\n",
    "    ('tfidf', vectorizer),\n",
    "    ('clf', OneVsRestClassifier(LogisticRegression(solver='liblinear')))\n",
    "])\n",
    "\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Prediction and evaluation\n",
    "y_pred = pipeline.predict(X_test)\n",
    "print(classification_report(y_test, y_pred, target_names=mlb.classes_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "coref",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
